---
title: "grobid_version_testing"
format: html
---

# Testing out different Grobid versions

### Loading the relevant packages, setting up variables

```{r}
# --- Configuration ---
PDF_SOURCE_DIR <- '~/Nextcloud/papercheck/pdfs/psych_science_250_oa'
OUTPUT_DIR <- '~/Nextcloud/papercheck/grobid_xmls/psych_science_250_oa'
NTFY_URL <- 'https://ntfy.jakubwerner.com/papercheck'
CORRIGENDUM_PAPERS_START_DICT <- list( # maps for which papers we have to specify start=X
    "0956797617710785.pdf" = 6,
    "0956797618795679.pdf" = 2,
    "0956797618815482.pdf" = 2,
    "0956797619830329.pdf" = 2,
    "0956797620959594.pdf" = 4
)
GROBID_VERSION_TO_ENDPOINT <- list(
    "0.8.2-delft" = "http://devserver.panda-pythagorean.ts.net:8070/",
    "0.8.2-crf" = "http://devserver.panda-pythagorean.ts.net:8072/",
    "0.8.3-SNAPSHOT-20250914-delft" = "http://devserver.panda-pythagorean.ts.net:8074/",
    "0.8.3-SNAPSHOT-20250914-crf" = "http://devserver.panda-pythagorean.ts.net:8076/"
)

library(papercheck)
```

### Now, convert the PDFs with pdf2grobid into distinct subfolders for each of the grobid versions

### First, without consolidation of citations, headers, and funders

```{r}

pdf_files <- list.files(PDF_SOURCE_DIR, pattern = "\\.pdf$", full.names = TRUE)
start_values <- CORRIGENDUM_PAPERS_START_DICT
# for all other papers, start = 1

for (grobid_version in names(GROBID_VERSION_TO_ENDPOINT)) {
    grobid_endpoint <- GROBID_VERSION_TO_ENDPOINT[[grobid_version]]
    file_path_unconsolidated <- file.path(OUTPUT_DIR, paste0(grobid_version, "_unconsolidated"))
    dir.create(file_path_unconsolidated, showWarnings = FALSE, recursive = TRUE)
    file_path_consolidated <- file.path(OUTPUT_DIR, paste0(grobid_version, "_consolidated_glutton_v1"))
    dir.create(file_path_consolidated, showWarnings = FALSE, recursive = TRUE)
    # let's process all the files in the PDF_SOURCE_DIR
    flush.console()
    print(paste("Processing", length(pdf_files), "files with Grobid version", grobid_version))
    for (pdf_file in pdf_files) {
        print(paste("Processing file:", pdf_file))
        flush.console()
        pdf_basename <- basename(pdf_file)
        xml_basename <- sub("\\.pdf$", ".xml", pdf_basename)
        xml_path_unconsolidated <- file.path(file_path_unconsolidated, xml_basename)
        xml_path_consolidated <- file.path(file_path_consolidated, xml_basename)
        
        print(paste("Processing unconsolidated XML for file:", pdf_basename))
        if (!file.exists(xml_path_unconsolidated)) {
            papercheck::pdf2grobid(pdf_file, save_path = file_path_unconsolidated,
                               grobid_url = grobid_endpoint,
                               start = start_values[[pdf_basename]],
                               end = -1,
                               consolidateCitations = 0,
                               consolidateHeader = 0,
                               consolidateFunders = 0)
        } else {
            print("Unconsolidated XML already exists, skipping.")
        }
        
        print(paste("Processing consolidated XML for file:", pdf_basename))
        if (!file.exists(xml_path_consolidated)) {
            papercheck::pdf2grobid(pdf_file, save_path = file_path_consolidated,
                               grobid_url = grobid_endpoint,
                               start = start_values[[pdf_basename]],
                               end = -1,
                               consolidateCitations = 1,
                               consolidateHeader = 1,
                               consolidateFunders = 1
                               )
        } else {
            print("Consolidated XML already exists, skipping.")
        }
        flush.console()
    }
    httr::POST(NTFY_URL, body = paste("Finished processing with Grobid version", grobid_version))
}

```

```{r}
psychsci = papercheck::read('~/Nextcloud/papercheck/grobid_xmls/psych_science_250_oa/0.8.3-SNAPSHOT-20250914-delft_consolidated_glutton_v1/0956797614527830.xml')

papercheck::info_table(psychsci, c("title", "keywords", "doi", "description"))
```

```{r}
papercheck::author_table(psychsci)
```

```{r}
psychsci$bib
```

```{r}
psychsci$xrefs
```

```{r}
papercheck::search_text(psychsci, return = "div")
```

```{r}
source("scripts/create_paper_table.R")

paper <- papercheck::read("~/Nextcloud/papercheck/grobid_xmls/psych_science_250_oa/0.8.3-SNAPSHOT-20250914-delft_consolidated_glutton_v1/0956797614527830.xml")

pt = create_paper_table(paper)


pt
```

```{r}
# --- Build paper tables for every Grobid version & paper ---
# Requires that the XMLs have already been generated in the earlier chunk.

timestamp <- format(Sys.time(), "%Y%m%d_%H%M%S")
all_tables <- list()

```

\`\`\`
